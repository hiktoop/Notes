# 文件系统

要求：

- 文件系统要从磁盘复现出命名目录树和文件，记录文件块的标识以及记录哪些块是空闲的

- 支持崩溃恢复，保证数据一致性

- 多进程同时操作文件系统，文件系统应该持有不变量

- 对热块进行缓存

## 概要

xv6 文件系统实现为这样七层：

![](../../iamge/xv6/Screenshot%20from%202023-09-19%2017-37-18.png)

Disk 层从 virtio 硬件驱动读写块，Buffer cache 层缓存磁盘块并同步访问；确保同一时间只有一个进程可以修改存储在任意特定块上个数据；Logging 层使得上层能够把对多个块的更新封装到一个事物里，并确保更新是原子的(崩溃时所有已更新或所有未更新)；inode 层提供抽象 inode 结构，i-number 对应于每个单独的文件，并存储文件数据所在的块；DIrcrtory 层规定，每个目录作为一个特殊的 inode，其文件内容是连续的目录项(文件名和 i-number)；Pathname 层提供了分层的路径名，通过递归查找对其进行解析；File descriptor 层通过文件系统接口抽象了许多 Unix 资源(e.g.,pipe, devices, files, etc)，减轻了应用程序员的负担。

xv6 使用 buf 表示一块 block 和其他信息

磁盘的块分布结构如下所示：

| boot | super | log | inodes | useBitmap | data... |
| ---- | ----- | --- | ------ | --------- | ------- |

有两个块用于 log，三个块用于 inodes，两个块用于 useBitmap，其他用于存储数据块，开始时使用 mkfs 将超级块填上相应的数据

## Buffer cache layer

主要任务(bio.c)：

1. 同步访问磁盘，确保每个块在内存中只有一个副本并且同一时间只有一个进程使用它

2. 缓存热块

具体实现看 bio_.md

## Logging layer

同一个动作可能有多个写操作，这时候崩溃就会造成数据不一致性。想象一下两个文件指向同一个块造成的悲哀吧！

xv6 通过一种简单的日志解决这个问题，一个系统调用并不直接将数据写入磁盘，而是把一系列将要进行的写操作的描述写到日志中，当日志把所有写操作记录下来后(没有文件系统调用的时候)，再把这段日志写入到磁盘，这时再把所有写操作写到磁盘，写完后再清除磁盘上的日志。

> 日志写入磁盘后接着数据写入磁盘，当写完还没来得及返回时崩溃了，之后虽然会再写一遍，但是不会造成数据的损坏。

这样的聚集写入同时也减少了 I/O 操作，使得文件系统能支持更多的并发写。但是 log 在磁盘的大小限制了一次写入块的数量不能大于日志空间，这造成了两个后果：一个单独的系统调用不能写比日志空间更多的块，比如对大文件的写和 unlink 操作，对于前者，xv6 将写入分割成多次的小型写来适应日志空间，后者不是问题，因为 xv6 只用一个 usebBitmap 块；另一个后果是一个系统调用只能在满足日志块的情况下才能进行。

代码分析在 log_

## inode layer

## file
